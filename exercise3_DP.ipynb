{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydriller in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: gitpython in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from pydriller) (3.1.40)\n",
      "Requirement already satisfied: pytz in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from pydriller) (2023.3.post1)\n",
      "Requirement already satisfied: types-pytz in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from pydriller) (2023.3.1.1)\n",
      "Requirement already satisfied: lizard in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from pydriller) (1.17.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from gitpython->pydriller) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\adam\\anaconda3\\envs\\utils_env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydriller import Repository\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clone code from the repo and save it for code portability -> via normal git clone\n",
    "url = \"https://github.com/apache/kafka\"\n",
    "repo_path = os.path.join(os.getcwd(), 'kafka')\n",
    "clone = f\"git clone {url} {repo_path}\" \n",
    "\n",
    "os.system(clone) # Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the tag 3.6.0\n",
    "os.chdir(repo_path)\n",
    "os.system(\"git checkout 3.6.0\")\n",
    "# back to the \"home\" folder\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_tag = \"3.5.1\"\n",
    "from_date=dt.datetime(2023, 7, 14, 18, 51, 0)\n",
    "\n",
    "to_tag = \"3.6.0\"\n",
    "to_date=dt.datetime(2023, 9, 29, 6, 56, 0)\n",
    "\n",
    "# Using datetimes of the releases, since tags don't yield any commits\n",
    "# Open question \n",
    "# repo = Repository(path_to_repo=repo_path, from_tag=to_tag, to_tag=from_tag)\n",
    "repo = Repository(path_to_repo=repo_path, since=from_date, to=to_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of all current java files\n",
    "import os\n",
    "\n",
    "def get_unique_java_files(directory):\n",
    "    unique_files = set()\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".java\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # remove the repo path from the file path\n",
    "                file_path = file_path.replace(directory+\"\\\\\", \"\")\n",
    "                unique_files.add(file_path)\n",
    "    return list(unique_files)\n",
    "\n",
    "# Replace 'your_repo_directory' with the path to your repository\n",
    "unique_files = get_unique_java_files(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize matrix\n",
    "import numpy as np\n",
    "\n",
    "time_windows = [24, 48, 72, 168]  # time windows in hours\n",
    "matrices = {window: np.zeros((len(unique_files), len(unique_files))) for window in time_windows}\n",
    "file_index_map = {file: index for index, file in enumerate(unique_files)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_file_to_matrices(file, file_index_map, matrices):\n",
    "    if file not in file_index_map:\n",
    "        new_index = len(file_index_map)\n",
    "        file_index_map[file] = new_index\n",
    "        unique_files.append(file)  # Update the unique_files list\n",
    "        \n",
    "        for window in matrices:\n",
    "            # Expand each matrix for the new file\n",
    "            matrices[window] = np.pad(matrices[window], ((0, 1), (0, 1)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def update_matrices(commit, matrices, file_index_map):\n",
    "    commit_time = commit.committer_date  # Adjusted to use your attribute\n",
    "\n",
    "    for file in commit.modified_files:\n",
    "        # Accessing filename correctly as per your example\n",
    "        filename = file.new_path if file.new_path else file.old_path\n",
    "        add_file_to_matrices(filename, file_index_map, matrices)\n",
    "\n",
    "    modified_file_indices = [file_index_map[file.new_path if file.new_path else file.old_path] for file in commit.modified_files]\n",
    "\n",
    "    for i in modified_file_indices:\n",
    "        for j in modified_file_indices:\n",
    "            if i != j:  # Skip incrementing for the same file\n",
    "                for window in time_windows:\n",
    "                    if commit_time - commit.committer_date <= timedelta(hours=window):\n",
    "                        matrices[window][i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for commit in Repository(path_to_repo=repo_path, only_modifications_with_file_types=['.java']).traverse_commits():\n",
    "    update_matrices(commit, matrices, file_index_map)\n",
    "    i -= 1\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def matrices_to_dataframe(matrices, unique_files):\n",
    "    df_list = []\n",
    "    for window, matrix in matrices.items():\n",
    "        df = pd.DataFrame(matrix, index=unique_files, columns=unique_files)\n",
    "        df = df.stack().reset_index()\n",
    "        df.columns = ['File1', 'File2', 'Count']\n",
    "        df['Time_Window'] = window\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "result_df = matrices_to_dataframe(matrices, unique_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filter out pairs with zero counts\n",
    "result_df = result_df[result_df['Count'] > 0]\n",
    "\n",
    "# Sort, reset index, etc.\n",
    "result_df = result_df.sort_values(by=['Count'], ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
